# this config is for dataset GeoQA
cache_file_h5py: "../file_data/AAAI/math_data_bert.h5"
cache_file_pickle: "../file_data/AAAI/label2index.pkl"
maxlen: 150 # 句子最大长度
epochs: 50
batch_size: 64 # 批处理尺寸, 感觉原则上越大越好,尤其是样本不均衡的时候, batch_size设置影响比较大
alpha: 4 # new model 的 loss 中的 alpha
hidden_size: 768 # roberta
num_classes_list: [45]
l_patience: 8  # patience for early stopping
b_patience: 10 # patience for basic model with a bigger patience